# ğŸ¤– Robots.txt â€” SEO + LLMs + Social Crawlers

Este repositÃ³rio contÃ©m a configuraÃ§Ã£o oficial do **robots.txt** do site  
ğŸ‘‰ **https://japiim.com.br**

O objetivo Ã© **permitir indexaÃ§Ã£o e leitura por buscadores, LLMs e bots de preview**, ao mesmo tempo em que **bloqueia crawlers abusivos e protege Ã¡reas sensÃ­veis** da aplicaÃ§Ã£o.

---

## ğŸ¯ Objetivos da configuraÃ§Ã£o

- âœ… OtimizaÃ§Ã£o para **SEO tradicional** (Google, Bing)
- âœ… DisponibilizaÃ§Ã£o clara para **LLMs / IA** (ChatGPT, Claude, Perplexity, OpenAI Search)
- âœ… Suporte a **bots de redes sociais** (preview de links)
- âŒ Bloqueio de bots conhecidos por **scraping agressivo**
- ğŸ”’ ProteÃ§Ã£o de rotas privadas e administrativas
- ğŸŒ CompatÃ­vel com **SPA (Vue.js)** + **API (FastAPI)**

---

## ğŸ¤– Bots explicitamente PERMITIDOS

### ğŸ” Buscadores
- Googlebot
- Bingbot
- BingPreview

### ğŸ§  LLMs / IA
- GPTBot
- OAI-SearchBot
- ClaudeBot
- Claude-Web
- PerplexityBot

### ğŸ“£ Social / Preview
- FacebookExternalHit
- FacebookBot
- Twitterbot
- LinkedInBot

### ğŸ› ï¸ SEO
- Screaming Frog SEO Spider

---

## ğŸš« Bots explicitamente BLOQUEADOS

Os bots abaixo sÃ£o conhecidos por **scraping agressivo**, uso comercial nÃ£o autorizado ou consumo excessivo de recursos:

- EtaoSpider
- CCBot (Common Crawl)
- Amazonbot
- FacebookBot-Mobile
- Bytespider (ByteDance)
- PetalBot (Huawei)

---

## ğŸ”’ Rotas protegidas (para todos os bots)

Mesmo bots permitidos **nÃ£o podem acessar**:

```txt
/auth/
/admin/
/private/
/api/
